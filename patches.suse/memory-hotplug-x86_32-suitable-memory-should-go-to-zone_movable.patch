From: Wang Nan <wangnan0@huawei.com>
Subject: memory-hotplug: x86_32: suitable memory should go to ZONE_MOVABLE

References: fate#316483
Patch-mainline: v3.17-rc1
Git-commit: 03d4be64603e2dc1bfa624bc436869d73340723e

This patch introduces zone_for_memory() to arch_add_memory() on x86_32 to
ensure new, higher memory added into ZONE_MOVABLE if movable zone has
already setup.

Signed-off-by: Wang Nan <wangnan0@huawei.com>
Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
Signed-off-by: Mel Gorman <mgorman@suse.de>
---

 arch/x86/mm/init_32.c |    3 ++-
 1 file changed, 2 insertions(+), 1 deletion(-)

diff -puN arch/x86/mm/init_32.c~memory-hotplug-x86_32-suitable-memory-should-go-to-zone_movable arch/x86/mm/init_32.c
--- a/arch/x86/mm/init_32.c~memory-hotplug-x86_32-suitable-memory-should-go-to-zone_movable
+++ a/arch/x86/mm/init_32.c
@@ -825,7 +825,8 @@ void __init mem_init(void)
 int arch_add_memory(int nid, u64 start, u64 size)
 {
 	struct pglist_data *pgdata = NODE_DATA(nid);
-	struct zone *zone = pgdata->node_zones + ZONE_HIGHMEM;
+	struct zone *zone = pgdata->node_zones +
+		zone_for_memory(nid, start, size, ZONE_HIGHMEM);
 	unsigned long start_pfn = start >> PAGE_SHIFT;
 	unsigned long nr_pages = size >> PAGE_SHIFT;
 
